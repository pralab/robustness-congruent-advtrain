import os
import pandas as pd
import numpy as np
from utils.utils import MODEL_NAMES, join
from utils.eval import compute_common_nflips
from utils.data import sort_df
import pickle
import math


pd.set_option('display.max_columns', None)


def hyperparams_table(root='results'):
    # 4 Folders, clean/advx and standard/AT
    root_clean = join(root, 'day-25-01-2023_hr-15-38-00_epochs-12_batchsize-500_CLEAN_TR')
    root_advx = f"{root_clean}/advx_ft"
    root_clean_AT = join(root, 'day-30-01-2023_hr-10-01-02_epochs-12_batchsize-500_ADV_TR')
    root_advx_AT = f"{root_clean_AT}/advx_ft"


    # Table for standard training
    df_clean = pd.read_csv(join(root_clean, 'all_models_results.csv'))
    df_advx = pd.read_csv(join(root_advx, 'all_models_results.csv'))
    df_clean.drop(['PFR1', 'PFR(FT)'], axis=1, inplace=True)
    df_advx = df_advx[['Acc0', 'Acc1', 'Acc(FT)', 'NFR1', 'NFR(FT)']].rename(
        columns={'Acc0': 'Rob Acc0', 'Acc1': 'Rob Acc1', 'NFR1': 'Rob NFR1',
                 'Acc(FT)': 'Rob Acc(FT)', 'NFR(FT)': 'Rob NFR(FT)'})
    df = pd.concat([df_clean, df_advx], axis=1)
    # At this point df has all results of PCT, for all hyperparams, both for clean and adv data, acc, NFR ecc

    # Table for AT
    df_clean_at = pd.read_csv(join(root_clean_AT, 'all_models_results.csv'))
    df_advx_at = pd.read_csv(join(root_advx_AT, 'all_models_results.csv'))
    df_clean_at.drop(['PFR1', 'PFR(FT)'], axis=1, inplace=True)
    df_advx_at = df_advx_at[['Acc0', 'Acc1', 'Acc(FT)', 'NFR1', 'NFR(FT)']].rename(
        columns={'Acc0': 'Rob Acc0', 'Acc1': 'Rob Acc1', 'NFR1': 'Rob NFR1',
                 'Acc(FT)': 'Rob Acc(FT)', 'NFR(FT)': 'Rob NFR(FT)'})
    df_at = pd.concat([df_clean_at, df_advx_at], axis=1)
    # Same as df, but all the results with adversarial training

    # Merge the 2 tables
    df['AT'] = False
    df_at['AT'] = True
    df = pd.concat([df, df_at])
    df.reset_index(inplace=True, drop=True)

    # Load and compute common churn between clean and advx data
    nf_idxs = {}
    for root_i, name in zip((root_clean, root_advx, root_clean_AT, root_advx_AT),
                          ("root_clean", "root_advx", "root_clean_AT", "root_advx_AT")):
        with open(join(root_i, 'all_nf_idxs.pkl'), 'rb') as f:
            nf_idxs[name] = pickle.load(f)

    common_nfs = []
    for i, r in df.iterrows():
        nf_idxs_clean = nf_idxs['root_clean' if not r['AT'] else 'root_clean_AT']
        nf_idxs_clean = nf_idxs_clean[r['Models ID']][r['Loss']][r['Hparams']]
        nf_idxs_advx = nf_idxs['root_advx' if not r['AT'] else 'root_advx_AT']
        nf_idxs_advx = nf_idxs_advx[r['Models ID']][r['Loss']][r['Hparams']]
        nf_idxs_clean = nf_idxs_clean[:nf_idxs_advx.shape[0]]
        _, _, common_nfr = compute_common_nflips(nf_idxs_clean, nf_idxs_advx)
        # nfr_row = nf_idxs_clean.mean()*100
        common_nfs.append(common_nfr*100)

    # add the common churn and sum column
    df['NFR (Both)'] = common_nfs
    df['NFR(Sum)'] = df['NFR(FT)'] + df['Rob NFR(FT)'] - df['NFR (Both)']


    print("")

def table_model_results(model_sel=(1,3,5,6),
                        losses=('PCT', 'MixMSE', 'MixMSE(NF)'),
                        diff=False, perc=False,
                        root='results'):
    """
    This function takes the results generated by evaluate_model.performance_csv.py
    """
    # 4 Folders, clean/advx and standard/AT
    root_clean = join(root, 'day-06-03-2023_hr-17-23-52_epochs-12_batchsize-500_HIGH_AB')
    root_advx = f"{root_clean}/advx_ft"
    root_clean_AT = join(root, 'day-06-03-2023_hr-17-23-52_epochs-12_batchsize-500_HIGH_AB')
    root_advx_AT = f"{root_clean_AT}/advx_ft"

    single_model_res_path = 'results/single_models_res'
    if not os.path.isdir(single_model_res_path):
        os.mkdir(single_model_res_path)

    # Table for standard training
    df_clean = pd.read_csv(join(root_clean, 'all_models_results.csv'))
    df_advx = pd.read_csv(join(root_advx, 'all_models_results.csv'))
    df_clean.drop(['PFR1', 'PFR(FT)'], axis=1, inplace=True)
    df_advx = df_advx[['Acc0', 'Acc1', 'Acc(FT)', 'NFR1', 'NFR(FT)']].rename(
        columns={'Acc0': 'Rob Acc0', 'Acc1': 'Rob Acc1', 'NFR1': 'Rob NFR1',
                 'Acc(FT)': 'Rob Acc(FT)', 'NFR(FT)': 'Rob NFR(FT)'})
    df = pd.concat([df_clean, df_advx], axis=1)
    # At this point df has all results of PCT, for all hyperparams, both for clean and adv data, acc, NFR ecc

    # Table for AT
    df_clean_at = pd.read_csv(join(root_clean_AT, 'all_models_results.csv'))
    df_advx_at = pd.read_csv(join(root_advx_AT, 'all_models_results.csv'))
    df_clean_at.drop(['PFR1', 'PFR(FT)'], axis=1, inplace=True)
    df_advx_at = df_advx_at[['Acc0', 'Acc1', 'Acc(FT)', 'NFR1', 'NFR(FT)']].rename(
        columns={'Acc0': 'Rob Acc0', 'Acc1': 'Rob Acc1', 'NFR1': 'Rob NFR1',
                 'Acc(FT)': 'Rob Acc(FT)', 'NFR(FT)': 'Rob NFR(FT)'})
    df_at = pd.concat([df_clean_at, df_advx_at], axis=1)
    # Same as df, but all the results with adversarial training

    # Merge the 2 tables
    df['AT'] = False
    df_at['AT'] = True
    df = pd.concat([df, df_at])

    # todo: when old-3_new-2 is computed remove!!!
    df = df[df["Models ID"] != "old-3_new-2"]

    df.reset_index(inplace=True, drop=True)

    # Load and compute common churn between clean and advx data
    nf_idxs = {}
    for root_i, name in zip((root_clean, root_advx, root_clean_AT, root_advx_AT),
                          ("root_clean", "root_advx", "root_clean_AT", "root_advx_AT")):
        with open(join(root_i, 'all_nf_idxs.pkl'), 'rb') as f:
            nf_idxs[name] = pickle.load(f)

    common_nfs = []
    for i, r in df.iterrows():
        nf_idxs_clean = nf_idxs['root_clean' if not r['AT'] else 'root_clean_AT']
        nf_idxs_clean = nf_idxs_clean[r['Models ID']][r['Loss']][r['Hparams']]
        nf_idxs_advx = nf_idxs['root_advx' if not r['AT'] else 'root_advx_AT']
        nf_idxs_advx = nf_idxs_advx[r['Models ID']][r['Loss']][r['Hparams']]
        nf_idxs_clean = nf_idxs_clean[:nf_idxs_advx.shape[0]]
        _, _, common_nfr = compute_common_nflips(nf_idxs_clean, nf_idxs_advx)
        # nfr_row = nf_idxs_clean.mean()*100
        common_nfs.append(common_nfr*100)

    # add the common churn and sum column
    df['NFR (Both)'] = common_nfs
    df['NFR(Sum)'] = df['NFR(FT)'] + df['Rob NFR(FT)'] - df['NFR (Both)']

    model_results_df_list = []
    diff_model_res_list = []
    keys = []

    # Here I take only one result for each model and loss, choosing bw hyperparameters
    for models_id in df['Models ID'].unique():
        # Check single models as single table
        print(f'{"-"*50}\n{models_id} - new -> {MODEL_NAMES[int(models_id.split("new-")[-1])]}')
        # models_id = df['Models ID'].unique()[3]
        keys.append(models_id)

        df_model = df.loc[df['Models ID'] == models_id]
        df_model.drop(['Models ID'], axis=1, inplace=True)

        df_model = sort_df(df_model, b=None, by='Rob NFR(FT)')
        hparams = list(df_model['Hparams'])
        df_model.reset_index(inplace=True, drop=True)

        model_results_df = pd.DataFrame(columns=['Acc', 'Rob Acc',
                                                 'NFR', 'Rob NFR', 'NFR (Both)',
                                                 'NFR (Sum)'])#, 'Hparams'])
        model_results_df.index.name = 'model'

        model_results_df.loc['old'] = [df_model['Acc0'][0],
                                       df_model['Rob Acc0'][0],
                                       None, None, None, None]
        model_results_df.loc['new'] = [df_model['Acc1'][0],
                                       df_model['Rob Acc1'][0],
                                       df_model['NFR1'][0],
                                       df_model['Rob NFR1'][0],
                                       df_model['NFR (Both)'][0],
                                       df_model['NFR1'][0]
                                       + df_model['Rob NFR1'][0]
                                       - df_model['NFR (Both)'][0]]
        for loss in losses:
            for at in [False, True]:
                loss_df = df_model.loc[(df_model['Loss'] == loss) & (df_model['AT'] == at)]
                if not loss_df.empty:
                    idx_name = loss if not at else f"{loss}-AT"
                    model_results_df.loc[idx_name] = [loss_df['Acc(FT)'].item(),
                                                      loss_df['Rob Acc(FT)'].item(),
                                                      loss_df['NFR(FT)'].item(),
                                                      loss_df['Rob NFR(FT)'].item(),
                                                      loss_df['NFR (Both)'].item(),
                                                      loss_df['NFR(FT)'].item()
                                                      + loss_df['Rob NFR(FT)'].item()
                                                      - loss_df['NFR (Both)'].item()
                                                      ]

        print(model_results_df)
        print(f"Hparams: {hparams}")
        model_results_df_list.append(model_results_df)
        model_results_df.to_csv(join(single_model_res_path, f"{models_id}.csv"),
                                float_format='%.2f')

    # model_results_df_list = pd.concat([model_results_df_list[i] for i in model_sel],
    #                                   keys=[keys[i] for i in model_sel])
    # keys = [key.replace('old-', 'M').replace('_new-', '_M') for key in keys]

    model_results_df_list = pd.concat(model_results_df_list,
                                      keys=keys)
    model_results_df_list.to_csv('results/all_results_table.csv')
    latex_table(model_results_df_list, diff=diff, perc=perc, dir_out=root)


def latex_table(df, diff=False, perc=False, dir_out='latex_files'):
    model_pairs = np.unique(np.array(list(zip(*df.index))[0])).tolist()

    idxs_best_list = []
    idxs_list = []
    idxs_at_list = []
    for model_pair in model_pairs:
        df_m = df.loc[model_pair]
        idxs = df_m.iloc[1:].idxmax()
        idxs.iloc[2:] = df_m.iloc[1:, 2:].idxmin()
        idxs_best_list.append(idxs)
        for i in range(2):
            sel_loss = [2+i, 4+i, 6+i][:(df_m.index.shape[0] - 2)//2]
            if diff:
                df_m.iloc[sel_loss, :] = df_m.iloc[sel_loss, :] - df_m.iloc[1, :]
            if perc:
                df_m.iloc[sel_loss, :] = (df_m.iloc[sel_loss, :] / df_m.iloc[1, :]).fillna(0)
            idxs = df_m.iloc[sel_loss].idxmax()
            idxs.iloc[2:] = df_m.iloc[sel_loss, 2:].idxmin()
            if i == 0:
                idxs_list.append(idxs)
            else:
                idxs_at_list.append(idxs)

    df = df.applymap(lambda x: f"{x:.2f}" if not math.isnan(x) else "-")

    keys = np.unique(list(zip(*df.index.to_list()))[0])
    keys = [key.replace('old-', 'M').replace('_new-', '-M') for key in keys]

    for model_pair, idxs, idxs_at, idxs_best, key in zip(model_pairs,
                                                         idxs_list,
                                                         idxs_at_list,
                                                         idxs_best_list,
                                                         keys):

        df_m = df.loc[model_pair]
        for col in df_m.columns:
            try:
                # value = df_m.loc[idxs.loc[col]][col]
                # df_m.loc[idxs.loc[col]][col] = r"\textcolor{blue}{" + value + r"}"
                #
                # value = df_m.loc[idxs_at.loc[col]][col]
                # df_m.loc[idxs_at.loc[col]][col] = r"\textcolor{red}{" + value + r"}"

                value = df.loc[model_pair].loc[idxs_best.loc[col]][col]
                df.loc[model_pair].loc[idxs_best.loc[col]][col] = r"\textbf{" + value + r"}"
            except:
                print("")

        new_index_name = key
        # new_index_name =r"\rotatebox[origin=t]{90}{" + new_index_name + r"}"
        new_index_name = r"\hline \multirow{6}{*}{" + new_index_name + "}"
        # new_index_name = model_pair
        df = df.rename(index={model_pair: new_index_name})
        print("")

    # df.rename(index={k:v in })
    # df = df.transpose()

    df_str = df.to_latex(
            caption="Models results", label="tab:ft_results",
            column_format="l|l|c c|c c c|c|", escape=False
        )
    df_str = df_str.replace(r'\begin{tabular}', r'\resizebox{0.99\linewidth}{!}{\begin{tabular}')
    df_str = df_str.replace(r'\end{tabular}', r'\hline \end{tabular}}')
    eof = ""
    if diff:
        eof = "_diff"
    if perc:
        eof = "_perc"
    with open(join(dir_out, f'models_results{eof}.tex'), 'w') as f:
        f.write(df_str)

    print("")


if __name__ == '__main__':
    model_sel = (1, 3, 5, 6)

    losses = ('PCT', 'MixMSE')  # , 'MixMSE(NF)')
    table_model_results(model_sel=model_sel, losses=losses, diff=False)

    # hyperparams_table(root='results/results_feb_2023_last_iter')

